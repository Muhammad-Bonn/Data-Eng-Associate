Daheeh YouTube Data Pipeline (Airflow + Docker) â€” This project automates the YouTube data extraction pipeline for the Arabic educational show "Ø§Ù„Ø¯Ø­ÙŠØ­ (Daheeh)" using Apache Airflow, Docker, and Python. It collects data from multiple YouTube playlists, enriches it with metadata (views, likes, duration, comments), and stores it automatically in a SQLite database â€” all inside a single Docker container. --- ## ğŸ§© Project Overview â€” Goal: Fetch, clean, and store YouTube video data from Daheeh playlists. â€” Tech Stack: Python 3, Google YouTube Data API v3, Apache Airflow (2.9.0), Docker + Docker Compose, SQLite. â€” The DAG runs automatically every Tuesday and Saturday at 9:30 PM, and once immediately after the container starts. --- ## ğŸ“ Project Structure â€” daheeh/ â†’ dags/ â†’ daheeh_pipeline.py (Airflow DAG) â†’ scripts/ â†’ extract_id.py, extract_metadata.py, main.py (ETL scripts) â†’ data/ â†’ youtube_database.db (output) â†’ requirements.txt â†’ Dockerfile â†’ docker-compose.yml â†’ entrypoint.sh --- ## âš™ï¸ How It Works â€” 1ï¸âƒ£ When the container starts, it creates a virtual environment, installs dependencies, and sets up Airflow. â€” 2ï¸âƒ£ The user enters their YouTube API key. â€” 3ï¸âƒ£ Airflow runs the DAG: extract_id.py â†’ extract_metadata.py â†’ main.py â†’ saves to SQLite. â€” 4ï¸âƒ£ The resulting database file (youtube_database.db) is saved in /data locally. --- ## ğŸš€ How to Run â€” 1. Clone: git clone https://github.com/Muhammad-Bonn/doc-data-airflow.git && cd doc-data-airflow/daheeh â€” 2. Build & Run: docker-compose up --build â€” 3. Enter API Key: (from Google Cloud Console) â€” 4. Access Airflow: Username airflow, Password airflow â†’ view DAG daheeh_youtube_pipeline. â€” 5. Check Results: sqlite3 data/youtube_database.db. --- ## ğŸ”® Future Improvements â€” Add cleaning and transformation steps, upload data to PostgreSQL/BigQuery, build dashboards (Streamlit/Metabase), and monitor API quota via Airflow sensors. --- ## ğŸ‘¥ Authors â€” Muhammad Ben, Omar, Hossam, and Zain â€” ğŸ› ï¸ Built with passion for data automation & open learning
